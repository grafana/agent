server:
  log_level: warn

metrics:
  wal_directory: /tmp/wal
  global:
    scrape_interval: 1m
  configs:
    - name: default
      host_filter: false
      scrape_configs:
        - job_name: local_scrape
          static_configs:
            - targets: ['127.0.0.1:12345']
              labels:
                cluster: 'localhost'
      remote_write:
      - url: https://prometheus-prod-01-eu-west-0.grafana.net/api/prom/push
        basic_auth:
          username: 297344
          password: eyJrIjoiNTIwOGRiNjIzMzYyMWQ2MTgwMzhhNzNhOGJlNjFjMmYzN2NlZTVmZCIsIm4iOiJhZG1pbi1hcGlrZXktbWFjYm9va3Byby0yIiwiaWQiOjU4MDc0N30=

integrations:
  ebpf:
    programs:
    # Count timers fired in the kernel
    - name: cachestat
      metrics:
        counters:
          - name: page_cache_ops_total
            help: Page cache operation counters by type
            table: counts
            labels:
              - name: op
                size: 8
                decoders:
                  - name: ksym
              - name: command
                size: 128
                decoders:
                  - name: string
                  - name: regexp
                    regexps:
                      - ^systemd-journal$
                      - ^syslog-ng$
      kprobes:
        add_to_page_cache_lru: do_count
        mark_page_accessed: do_count
        account_page_dirtied: do_count
        mark_buffer_dirty: do_count
      code: |
        #include <uapi/linux/ptrace.h>
        struct key_t {
            u64 ip;
            char command[128];
        };
        BPF_HASH(counts, struct key_t);
        int do_count(struct pt_regs *ctx) {
            struct key_t key = { .ip = PT_REGS_IP(ctx) - 1 };
            bpf_get_current_comm(&key.command, sizeof(key.command));
            counts.increment(key);
            return 0;
        }

